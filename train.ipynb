{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/proc_data_files/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/5.2.0-py3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/as3ek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 61.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading TRAIN images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 91.68it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 84.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading VAL images and captions, storing to file...\n",
      "\n",
      "\n",
      "Reading TEST images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import create_input_files\n",
    "\n",
    "create_input_files(dataset='data/caption_data_0_100.csv', \n",
    "                   image_folder='data/images/', \n",
    "                   captions_per_image=1000, \n",
    "                   min_word_freq=0, \n",
    "                   output_folder='data/proc_data_files/', \n",
    "                   max_len=20, \n",
    "                   key_max_len=10, \n",
    "                   num_images_to_train=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Imports\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from models import Encoder, DecoderWithAttention\n",
    "from datasets import *\n",
    "from utils import *\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "data_folder = 'data/proc_data_files/'  # folder with data files saved by create_input_files.py\n",
    "data_name = 'meme_1000_cap_per_img_0_min_word_freq'  # base name shared by data files\n",
    "\n",
    "# Model parameters\n",
    "emb_dim = 512  # dimension of word embeddings\n",
    "attention_dim = 512  # dimension of attention linear layers\n",
    "decoder_dim = 512  # dimension of decoder RNN\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead\n",
    "\n",
    "# Training parameters\n",
    "start_epoch = 0\n",
    "epochs = 120  # number of epochs to train for (if early stopping is not triggered)\n",
    "epochs_since_improvement = 0  # keeps track of number of epochs since there's been an improvement in validation BLEU\n",
    "batch_size = 32\n",
    "workers = 1  # for data-loading; right now, only 1 works with h5py\n",
    "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
    "decoder_lr = 4e-4  # learning rate for decoder\n",
    "grad_clip = 5.  # clip gradients at an absolute value of\n",
    "alpha_c = 1.  # regularization parameter for 'doubly stochastic attention', as in the paper\n",
    "best_bleu4 = 0.  # BLEU-4 score right now\n",
    "print_freq = 100  # print training/validation stats every __ batches\n",
    "fine_tune_encoder = False  # fine-tune encoder?\n",
    "checkpoint = None  # path to checkpoint, None if none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Training and validation.\n",
    "    \"\"\"\n",
    "\n",
    "    global best_bleu4, epochs_since_improvement, checkpoint, start_epoch, fine_tune_encoder, data_name, word_map\n",
    "\n",
    "    # Read word map\n",
    "    word_map_file = os.path.join(data_folder, 'WORDMAP_' + data_name + '.json')\n",
    "    with open(word_map_file, 'r') as j:\n",
    "        word_map = json.load(j)\n",
    "\n",
    "    # Initialize / load checkpoint\n",
    "    if checkpoint is None:\n",
    "        decoder = DecoderWithAttention(attention_dim=attention_dim,\n",
    "                                       embed_dim=emb_dim,\n",
    "                                       decoder_dim=decoder_dim,\n",
    "                                       vocab_size=len(word_map),\n",
    "                                       dropout=dropout)\n",
    "        decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),\n",
    "                                             lr=decoder_lr)\n",
    "        encoder = Encoder()\n",
    "        encoder.fine_tune(fine_tune_encoder)\n",
    "        encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                             lr=encoder_lr) if fine_tune_encoder else None\n",
    "\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        epochs_since_improvement = checkpoint['epochs_since_improvement']\n",
    "        best_bleu4 = checkpoint['bleu-4']\n",
    "        decoder = checkpoint['decoder']\n",
    "        decoder_optimizer = checkpoint['decoder_optimizer']\n",
    "        encoder = checkpoint['encoder']\n",
    "        encoder_optimizer = checkpoint['encoder_optimizer']\n",
    "        if fine_tune_encoder is True and encoder_optimizer is None:\n",
    "            encoder.fine_tune(fine_tune_encoder)\n",
    "            encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                                 lr=encoder_lr)\n",
    "\n",
    "    # Move to GPU, if available\n",
    "    decoder = decoder.to(device)\n",
    "    encoder = encoder.to(device)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # Custom dataloaders\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        CaptionDataset(data_folder, data_name, 'TRAIN', transform=transforms.Compose([normalize])),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        CaptionDataset(data_folder, data_name, 'VAL', transform=transforms.Compose([normalize])),\n",
    "        batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "\n",
    "    # Epochs\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "\n",
    "        # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
    "        if epochs_since_improvement == 20:\n",
    "            break\n",
    "        if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
    "            adjust_learning_rate(decoder_optimizer, 0.8)\n",
    "            if fine_tune_encoder:\n",
    "                adjust_learning_rate(encoder_optimizer, 0.8)\n",
    "\n",
    "        # One epoch's training\n",
    "        train(train_loader=train_loader,\n",
    "              encoder=encoder,\n",
    "              decoder=decoder,\n",
    "              criterion=criterion,\n",
    "              encoder_optimizer=encoder_optimizer,\n",
    "              decoder_optimizer=decoder_optimizer,\n",
    "              epoch=epoch)\n",
    "\n",
    "        # One epoch's validation\n",
    "        recent_bleu4 = validate(val_loader=val_loader,\n",
    "                                encoder=encoder,\n",
    "                                decoder=decoder,\n",
    "                                criterion=criterion)\n",
    "\n",
    "        # Check if there was an improvement\n",
    "        is_best = recent_bleu4 > best_bleu4\n",
    "        best_bleu4 = max(recent_bleu4, best_bleu4)\n",
    "        if not is_best:\n",
    "            epochs_since_improvement += 1\n",
    "            print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
    "        else:\n",
    "            epochs_since_improvement = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(data_name, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer,\n",
    "                        decoder_optimizer, recent_bleu4, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Performs one epoch's training.\n",
    "\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param criterion: loss layer\n",
    "    :param encoder_optimizer: optimizer to update encoder's weights (if fine-tuning)\n",
    "    :param decoder_optimizer: optimizer to update decoder's weights\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "\n",
    "    decoder.train()  # train mode (dropout and batchnorm is used)\n",
    "    encoder.train()\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss (per word decoded)\n",
    "    top5accs = AverageMeter()  # top5 accuracy\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Batches (Added keys to be used in the future)\n",
    "    for i, (imgs, caps, keys, caplens) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to GPU, if available\n",
    "        imgs = imgs.to(device)\n",
    "        caps = caps.to(device)\n",
    "        caplens = caplens.to(device)\n",
    "\n",
    "        # Forward prop.\n",
    "        imgs = encoder(imgs)\n",
    "        scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
    "\n",
    "        # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "        targets = caps_sorted[:, 1:]\n",
    "\n",
    "        # Remove timesteps that we didn't decode at, or are pads\n",
    "        # pack_padded_sequence is an easy trick to do this\n",
    "        scores, _ = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "        targets, _ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Add doubly stochastic attention regularization\n",
    "        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "\n",
    "        # Back prop.\n",
    "        decoder_optimizer.zero_grad()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(decoder_optimizer, grad_clip)\n",
    "            if encoder_optimizer is not None:\n",
    "                clip_gradient(encoder_optimizer, grad_clip)\n",
    "\n",
    "        # Update weights\n",
    "        decoder_optimizer.step()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.step()\n",
    "\n",
    "        # Keep track of metrics\n",
    "        top5 = accuracy(scores, targets, 5)\n",
    "        losses.update(loss.item(), sum(decode_lengths))\n",
    "        top5accs.update(top5, sum(decode_lengths))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data Load Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n",
    "                                                                          batch_time=batch_time,\n",
    "                                                                          data_time=data_time, loss=losses,\n",
    "                                                                          top5=top5accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, encoder, decoder, criterion):\n",
    "    \"\"\"\n",
    "    Performs one epoch's validation.\n",
    "\n",
    "    :param val_loader: DataLoader for validation data.\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param criterion: loss layer\n",
    "    :return: BLEU-4 score\n",
    "    \"\"\"\n",
    "    decoder.eval()  # eval mode (no dropout or batchnorm)\n",
    "    if encoder is not None:\n",
    "        encoder.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top5accs = AverageMeter()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    references = list()  # references (true captions) for calculating BLEU-4 score\n",
    "    hypotheses = list()  # hypotheses (predictions)\n",
    "\n",
    "    # Batches (Added keys and allkeys for later)\n",
    "    for i, (imgs, caps, keys, caplens, allcaps, allkeys) in enumerate(val_loader):\n",
    "\n",
    "        # Move to device, if available\n",
    "        imgs = imgs.to(device)\n",
    "        caps = caps.to(device)\n",
    "        caplens = caplens.to(device)\n",
    "\n",
    "        # Forward prop.\n",
    "        if encoder is not None:\n",
    "            imgs = encoder(imgs)\n",
    "        scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, caplens)\n",
    "\n",
    "        # Since we decoded starting with <start>, the targets are all words after <start>, up to <end>\n",
    "        targets = caps_sorted[:, 1:]\n",
    "\n",
    "        # Remove timesteps that we didn't decode at, or are pads\n",
    "        # pack_padded_sequence is an easy trick to do this\n",
    "        scores_copy = scores.clone()\n",
    "        scores, _ = pack_padded_sequence(scores, decode_lengths, batch_first=True)\n",
    "        targets, _ = pack_padded_sequence(targets, decode_lengths, batch_first=True)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Add doubly stochastic attention regularization\n",
    "        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "\n",
    "        # Keep track of metrics\n",
    "        losses.update(loss.item(), sum(decode_lengths))\n",
    "        top5 = accuracy(scores, targets, 5)\n",
    "        top5accs.update(top5, sum(decode_lengths))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Validation: [{0}/{1}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})\\t'.format(i, len(val_loader), batch_time=batch_time,\n",
    "                                                                            loss=losses, top5=top5accs))\n",
    "\n",
    "        # Store references (true captions), and hypothesis (prediction) for each image\n",
    "        # If for n images, we have n hypotheses, and references a, b, c... for each image, we need -\n",
    "        # references = [[ref1a, ref1b, ref1c], [ref2a, ref2b], ...], hypotheses = [hyp1, hyp2, ...]\n",
    "\n",
    "        # References\n",
    "        allcaps = allcaps[sort_ind]  # because images were sorted in the decoder\n",
    "        for j in range(allcaps.shape[0]):\n",
    "            img_caps = allcaps[j].tolist()\n",
    "            img_captions = list(\n",
    "                map(lambda c: [w for w in c if w not in {word_map['<start>'], word_map['<pad>']}],\n",
    "                    img_caps))  # remove <start> and pads\n",
    "            references.append(img_captions)\n",
    "\n",
    "        # Hypotheses\n",
    "        _, preds = torch.max(scores_copy, dim=2)\n",
    "        preds = preds.tolist()\n",
    "        temp_preds = list()\n",
    "        for j, p in enumerate(preds):\n",
    "            temp_preds.append(preds[j][:decode_lengths[j]])  # remove pads\n",
    "        preds = temp_preds\n",
    "        hypotheses.extend(preds)\n",
    "\n",
    "        assert len(references) == len(hypotheses)\n",
    "\n",
    "    # Calculate BLEU-4 scores\n",
    "    bleu4 = corpus_bleu(references, hypotheses)\n",
    "\n",
    "    print(\n",
    "        '\\n * LOSS - {loss.avg:.3f}, TOP-5 ACCURACY - {top5.avg:.3f}, BLEU-4 - {bleu}\\n'.format(\n",
    "            loss=losses,\n",
    "            top5=top5accs,\n",
    "            bleu=bleu4))\n",
    "\n",
    "    return bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/219]\tBatch Time 2.118 (2.118)\tData Load Time 0.166 (0.166)\tLoss 11.3139 (11.3139)\tTop-5 Accuracy 0.000 (0.000)\n",
      "Epoch: [0][100/219]\tBatch Time 0.290 (0.308)\tData Load Time 0.000 (0.002)\tLoss 6.5221 (7.5644)\tTop-5 Accuracy 40.052 (30.605)\n",
      "Epoch: [0][200/219]\tBatch Time 0.307 (0.299)\tData Load Time 0.000 (0.001)\tLoss 6.1619 (7.0295)\tTop-5 Accuracy 39.579 (34.368)\n",
      "Validation: [0/32]\tBatch Time 0.364 (0.364)\tLoss 8.1212 (8.1212)\tTop-5 Accuracy 19.536 (19.536)\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/software/standard/core/anaconda/5.2.0-py3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:503: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " * LOSS - 8.007, TOP-5 ACCURACY - 18.479, BLEU-4 - 1.262575531466194e-78\n",
      "\n",
      "Epoch: [1][0/219]\tBatch Time 0.449 (0.449)\tData Load Time 0.142 (0.142)\tLoss 6.2111 (6.2111)\tTop-5 Accuracy 37.469 (37.469)\n",
      "Epoch: [1][100/219]\tBatch Time 0.303 (0.291)\tData Load Time 0.000 (0.002)\tLoss 5.5070 (6.0712)\tTop-5 Accuracy 49.115 (41.713)\n",
      "Epoch: [1][200/219]\tBatch Time 0.295 (0.291)\tData Load Time 0.000 (0.001)\tLoss 5.6932 (6.0007)\tTop-5 Accuracy 47.087 (42.463)\n",
      "Validation: [0/32]\tBatch Time 0.348 (0.348)\tLoss 7.4979 (7.4979)\tTop-5 Accuracy 26.349 (26.349)\t\n",
      "\n",
      " * LOSS - 7.829, TOP-5 ACCURACY - 21.678, BLEU-4 - 2.2475891527506337e-78\n",
      "\n",
      "Epoch: [2][0/219]\tBatch Time 0.449 (0.449)\tData Load Time 0.147 (0.147)\tLoss 5.4376 (5.4376)\tTop-5 Accuracy 51.282 (51.282)\n",
      "Epoch: [2][100/219]\tBatch Time 0.292 (0.291)\tData Load Time 0.000 (0.002)\tLoss 5.8411 (5.6909)\tTop-5 Accuracy 45.714 (45.461)\n",
      "Epoch: [2][200/219]\tBatch Time 0.291 (0.290)\tData Load Time 0.000 (0.001)\tLoss 5.4883 (5.6675)\tTop-5 Accuracy 46.512 (45.793)\n",
      "Validation: [0/32]\tBatch Time 0.365 (0.365)\tLoss 7.4637 (7.4637)\tTop-5 Accuracy 25.212 (25.212)\t\n",
      "\n",
      " * LOSS - 7.741, TOP-5 ACCURACY - 22.595, BLEU-4 - 2.061629370082402e-78\n",
      "\n",
      "\n",
      "Epochs since last improvement: 1\n",
      "\n",
      "Epoch: [3][0/219]\tBatch Time 0.443 (0.443)\tData Load Time 0.146 (0.146)\tLoss 5.6603 (5.6603)\tTop-5 Accuracy 44.415 (44.415)\n",
      "Epoch: [3][100/219]\tBatch Time 0.287 (0.291)\tData Load Time 0.000 (0.002)\tLoss 5.5609 (5.4812)\tTop-5 Accuracy 48.042 (47.132)\n",
      "Epoch: [3][200/219]\tBatch Time 0.290 (0.290)\tData Load Time 0.000 (0.001)\tLoss 5.6134 (5.4514)\tTop-5 Accuracy 44.828 (47.538)\n",
      "Validation: [0/32]\tBatch Time 0.361 (0.361)\tLoss 8.4927 (8.4927)\tTop-5 Accuracy 19.572 (19.572)\t\n",
      "\n",
      " * LOSS - 7.765, TOP-5 ACCURACY - 23.313, BLEU-4 - 0.021120766786653537\n",
      "\n",
      "Epoch: [4][0/219]\tBatch Time 0.452 (0.452)\tData Load Time 0.145 (0.145)\tLoss 5.4583 (5.4583)\tTop-5 Accuracy 50.485 (50.485)\n",
      "Epoch: [4][100/219]\tBatch Time 0.284 (0.291)\tData Load Time 0.000 (0.002)\tLoss 5.3105 (5.2861)\tTop-5 Accuracy 48.913 (48.707)\n",
      "Epoch: [4][200/219]\tBatch Time 0.283 (0.291)\tData Load Time 0.000 (0.001)\tLoss 5.5754 (5.2666)\tTop-5 Accuracy 43.213 (49.173)\n",
      "Validation: [0/32]\tBatch Time 0.435 (0.435)\tLoss 7.9805 (7.9805)\tTop-5 Accuracy 23.701 (23.701)\t\n",
      "\n",
      " * LOSS - 7.728, TOP-5 ACCURACY - 24.031, BLEU-4 - 0.021872960618187425\n",
      "\n",
      "Epoch: [5][0/219]\tBatch Time 0.439 (0.439)\tData Load Time 0.145 (0.145)\tLoss 4.9715 (4.9715)\tTop-5 Accuracy 53.264 (53.264)\n",
      "Epoch: [5][100/219]\tBatch Time 0.294 (0.291)\tData Load Time 0.000 (0.002)\tLoss 5.2695 (5.1075)\tTop-5 Accuracy 48.259 (50.218)\n",
      "Epoch: [5][200/219]\tBatch Time 0.289 (0.290)\tData Load Time 0.000 (0.001)\tLoss 5.3207 (5.1059)\tTop-5 Accuracy 47.949 (50.325)\n",
      "Validation: [0/32]\tBatch Time 0.365 (0.365)\tLoss 7.7121 (7.7121)\tTop-5 Accuracy 25.753 (25.753)\t\n",
      "\n",
      " * LOSS - 7.749, TOP-5 ACCURACY - 24.529, BLEU-4 - 0.02548082156660115\n",
      "\n",
      "Epoch: [6][0/219]\tBatch Time 0.456 (0.456)\tData Load Time 0.147 (0.147)\tLoss 5.0506 (5.0506)\tTop-5 Accuracy 51.613 (51.613)\n",
      "Epoch: [6][100/219]\tBatch Time 0.286 (0.292)\tData Load Time 0.000 (0.002)\tLoss 4.5566 (4.9425)\tTop-5 Accuracy 55.742 (51.456)\n",
      "Epoch: [6][200/219]\tBatch Time 0.282 (0.291)\tData Load Time 0.000 (0.001)\tLoss 5.4181 (4.9390)\tTop-5 Accuracy 45.125 (51.752)\n",
      "Validation: [0/32]\tBatch Time 0.362 (0.362)\tLoss 7.9411 (7.9411)\tTop-5 Accuracy 24.149 (24.149)\t\n",
      "\n",
      " * LOSS - 7.841, TOP-5 ACCURACY - 24.858, BLEU-4 - 0.02322270092993859\n",
      "\n",
      "\n",
      "Epochs since last improvement: 1\n",
      "\n",
      "Epoch: [7][0/219]\tBatch Time 0.435 (0.435)\tData Load Time 0.145 (0.145)\tLoss 4.6778 (4.6778)\tTop-5 Accuracy 55.181 (55.181)\n",
      "Epoch: [7][100/219]\tBatch Time 0.287 (0.291)\tData Load Time 0.000 (0.002)\tLoss 4.8922 (4.7566)\tTop-5 Accuracy 51.554 (53.002)\n",
      "Epoch: [7][200/219]\tBatch Time 0.287 (0.291)\tData Load Time 0.000 (0.001)\tLoss 4.8745 (4.7986)\tTop-5 Accuracy 52.291 (52.611)\n",
      "Validation: [0/32]\tBatch Time 0.361 (0.361)\tLoss 8.0195 (8.0195)\tTop-5 Accuracy 23.333 (23.333)\t\n",
      "\n",
      " * LOSS - 7.856, TOP-5 ACCURACY - 24.718, BLEU-4 - 0.02488252110230559\n",
      "\n",
      "\n",
      "Epochs since last improvement: 2\n",
      "\n",
      "Epoch: [8][0/219]\tBatch Time 0.436 (0.436)\tData Load Time 0.144 (0.144)\tLoss 4.7306 (4.7306)\tTop-5 Accuracy 52.846 (52.846)\n",
      "Epoch: [8][100/219]\tBatch Time 0.287 (0.291)\tData Load Time 0.000 (0.002)\tLoss 4.5642 (4.6347)\tTop-5 Accuracy 55.769 (53.919)\n",
      "Epoch: [8][200/219]\tBatch Time 0.264 (0.290)\tData Load Time 0.000 (0.001)\tLoss 4.8413 (4.6569)\tTop-5 Accuracy 50.462 (53.750)\n",
      "Validation: [0/32]\tBatch Time 0.365 (0.365)\tLoss 8.0991 (8.0991)\tTop-5 Accuracy 23.197 (23.197)\t\n",
      "\n",
      " * LOSS - 7.901, TOP-5 ACCURACY - 24.978, BLEU-4 - 0.032042753982548446\n",
      "\n",
      "Epoch: [9][0/219]\tBatch Time 0.440 (0.440)\tData Load Time 0.147 (0.147)\tLoss 4.7117 (4.7117)\tTop-5 Accuracy 51.275 (51.275)\n",
      "Epoch: [9][100/219]\tBatch Time 0.299 (0.291)\tData Load Time 0.000 (0.002)\tLoss 4.5041 (4.4843)\tTop-5 Accuracy 56.977 (55.272)\n",
      "Epoch: [9][200/219]\tBatch Time 0.296 (0.290)\tData Load Time 0.000 (0.001)\tLoss 4.3813 (4.5201)\tTop-5 Accuracy 57.108 (54.811)\n",
      "Validation: [0/32]\tBatch Time 0.362 (0.362)\tLoss 8.3983 (8.3983)\tTop-5 Accuracy 23.708 (23.708)\t\n",
      "\n",
      " * LOSS - 7.969, TOP-5 ACCURACY - 25.047, BLEU-4 - 0.031198292314028885\n",
      "\n",
      "\n",
      "Epochs since last improvement: 1\n",
      "\n",
      "Epoch: [10][0/219]\tBatch Time 0.452 (0.452)\tData Load Time 0.147 (0.147)\tLoss 4.5444 (4.5444)\tTop-5 Accuracy 54.187 (54.187)\n",
      "Epoch: [10][100/219]\tBatch Time 0.295 (0.291)\tData Load Time 0.000 (0.002)\tLoss 4.4082 (4.3447)\tTop-5 Accuracy 55.172 (56.363)\n",
      "Epoch: [10][200/219]\tBatch Time 0.303 (0.290)\tData Load Time 0.000 (0.001)\tLoss 4.7709 (4.3781)\tTop-5 Accuracy 51.339 (56.075)\n",
      "Validation: [0/32]\tBatch Time 0.358 (0.358)\tLoss 8.0411 (8.0411)\tTop-5 Accuracy 26.481 (26.481)\t\n",
      "\n",
      " * LOSS - 7.974, TOP-5 ACCURACY - 24.679, BLEU-4 - 0.03452761064726995\n",
      "\n",
      "Epoch: [11][0/219]\tBatch Time 0.452 (0.452)\tData Load Time 0.148 (0.148)\tLoss 4.1105 (4.1105)\tTop-5 Accuracy 59.057 (59.057)\n",
      "Epoch: [11][100/219]\tBatch Time 0.293 (0.291)\tData Load Time 0.000 (0.002)\tLoss 4.3160 (4.2187)\tTop-5 Accuracy 55.416 (57.704)\n",
      "Epoch: [11][200/219]\tBatch Time 0.287 (0.290)\tData Load Time 0.000 (0.001)\tLoss 4.1786 (4.2574)\tTop-5 Accuracy 60.109 (57.156)\n",
      "Validation: [0/32]\tBatch Time 0.362 (0.362)\tLoss 7.6518 (7.6518)\tTop-5 Accuracy 28.221 (28.221)\t\n",
      "\n",
      " * LOSS - 8.068, TOP-5 ACCURACY - 24.200, BLEU-4 - 0.029424218625075205\n",
      "\n",
      "\n",
      "Epochs since last improvement: 1\n",
      "\n",
      "Epoch: [12][0/219]\tBatch Time 0.448 (0.448)\tData Load Time 0.149 (0.149)\tLoss 4.2346 (4.2346)\tTop-5 Accuracy 57.552 (57.552)\n",
      "Epoch: [12][100/219]\tBatch Time 0.281 (0.291)\tData Load Time 0.000 (0.002)\tLoss 4.0489 (4.1081)\tTop-5 Accuracy 61.257 (58.705)\n",
      "Epoch: [12][200/219]\tBatch Time 0.288 (0.291)\tData Load Time 0.000 (0.001)\tLoss 4.2542 (4.1220)\tTop-5 Accuracy 55.096 (58.797)\n",
      "Validation: [0/32]\tBatch Time 0.404 (0.404)\tLoss 8.3713 (8.3713)\tTop-5 Accuracy 25.312 (25.312)\t\n",
      "\n",
      " * LOSS - 8.143, TOP-5 ACCURACY - 24.998, BLEU-4 - 0.028117889895055963\n",
      "\n",
      "\n",
      "Epochs since last improvement: 2\n",
      "\n",
      "Epoch: [13][0/219]\tBatch Time 0.450 (0.450)\tData Load Time 0.147 (0.147)\tLoss 4.0775 (4.0775)\tTop-5 Accuracy 59.474 (59.474)\n",
      "Epoch: [13][100/219]\tBatch Time 0.295 (0.292)\tData Load Time 0.000 (0.002)\tLoss 3.7627 (3.9880)\tTop-5 Accuracy 64.138 (60.466)\n",
      "Epoch: [13][200/219]\tBatch Time 0.289 (0.291)\tData Load Time 0.000 (0.001)\tLoss 4.0303 (4.0090)\tTop-5 Accuracy 59.799 (60.120)\n",
      "Validation: [0/32]\tBatch Time 0.360 (0.360)\tLoss 7.7565 (7.7565)\tTop-5 Accuracy 23.964 (23.964)\t\n",
      "\n",
      " * LOSS - 8.282, TOP-5 ACCURACY - 24.170, BLEU-4 - 0.031719610173482175\n",
      "\n",
      "\n",
      "Epochs since last improvement: 3\n",
      "\n",
      "Epoch: [14][0/219]\tBatch Time 0.447 (0.447)\tData Load Time 0.148 (0.148)\tLoss 3.8992 (3.8992)\tTop-5 Accuracy 64.141 (64.141)\n",
      "Epoch: [14][100/219]\tBatch Time 0.283 (0.291)\tData Load Time 0.000 (0.002)\tLoss 4.1914 (3.8610)\tTop-5 Accuracy 59.091 (62.436)\n",
      "Epoch: [14][200/219]\tBatch Time 0.289 (0.290)\tData Load Time 0.000 (0.001)\tLoss 3.5092 (3.8821)\tTop-5 Accuracy 66.197 (62.143)\n",
      "Validation: [0/32]\tBatch Time 0.351 (0.351)\tLoss 8.1468 (8.1468)\tTop-5 Accuracy 26.441 (26.441)\t\n",
      "\n",
      " * LOSS - 8.301, TOP-5 ACCURACY - 24.509, BLEU-4 - 0.04025448833163941\n",
      "\n",
      "Epoch: [15][0/219]\tBatch Time 0.435 (0.435)\tData Load Time 0.147 (0.147)\tLoss 3.5088 (3.5088)\tTop-5 Accuracy 68.817 (68.817)\n",
      "Epoch: [15][100/219]\tBatch Time 0.292 (0.290)\tData Load Time 0.000 (0.002)\tLoss 3.9609 (3.7364)\tTop-5 Accuracy 62.060 (64.036)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/219]\tBatch Time 0.285 (0.290)\tData Load Time 0.000 (0.001)\tLoss 3.6134 (3.7627)\tTop-5 Accuracy 65.217 (63.728)\n",
      "Validation: [0/32]\tBatch Time 0.367 (0.367)\tLoss 8.5565 (8.5565)\tTop-5 Accuracy 24.047 (24.047)\t\n",
      "\n",
      " * LOSS - 8.360, TOP-5 ACCURACY - 24.320, BLEU-4 - 0.028669435150576756\n",
      "\n",
      "\n",
      "Epochs since last improvement: 1\n",
      "\n",
      "Epoch: [16][0/219]\tBatch Time 0.459 (0.459)\tData Load Time 0.146 (0.146)\tLoss 3.5177 (3.5177)\tTop-5 Accuracy 65.741 (65.741)\n",
      "Epoch: [16][100/219]\tBatch Time 0.291 (0.291)\tData Load Time 0.000 (0.002)\tLoss 3.8503 (3.5939)\tTop-5 Accuracy 64.216 (66.343)\n",
      "Epoch: [16][200/219]\tBatch Time 0.289 (0.290)\tData Load Time 0.000 (0.001)\tLoss 3.5147 (3.6412)\tTop-5 Accuracy 67.574 (65.729)\n",
      "Validation: [0/32]\tBatch Time 0.382 (0.382)\tLoss 8.5344 (8.5344)\tTop-5 Accuracy 24.138 (24.138)\t\n",
      "\n",
      " * LOSS - 8.562, TOP-5 ACCURACY - 23.463, BLEU-4 - 0.028872872444183288\n",
      "\n",
      "\n",
      "Epochs since last improvement: 2\n",
      "\n",
      "Epoch: [17][0/219]\tBatch Time 0.435 (0.435)\tData Load Time 0.146 (0.146)\tLoss 3.5902 (3.5902)\tTop-5 Accuracy 66.313 (66.313)\n",
      "Epoch: [17][100/219]\tBatch Time 0.286 (0.290)\tData Load Time 0.000 (0.002)\tLoss 3.7036 (3.4968)\tTop-5 Accuracy 64.463 (68.208)\n",
      "Epoch: [17][200/219]\tBatch Time 0.293 (0.290)\tData Load Time 0.000 (0.001)\tLoss 3.3812 (3.5230)\tTop-5 Accuracy 69.598 (67.684)\n",
      "Validation: [0/32]\tBatch Time 0.368 (0.368)\tLoss 8.3922 (8.3922)\tTop-5 Accuracy 22.193 (22.193)\t\n",
      "\n",
      " * LOSS - 8.573, TOP-5 ACCURACY - 23.223, BLEU-4 - 0.03716381481260889\n",
      "\n",
      "\n",
      "Epochs since last improvement: 3\n",
      "\n",
      "Epoch: [18][0/219]\tBatch Time 0.436 (0.436)\tData Load Time 0.147 (0.147)\tLoss 3.3081 (3.3081)\tTop-5 Accuracy 72.727 (72.727)\n",
      "Epoch: [18][100/219]\tBatch Time 0.288 (0.292)\tData Load Time 0.000 (0.002)\tLoss 3.4988 (3.3525)\tTop-5 Accuracy 68.464 (70.225)\n",
      "Epoch: [18][200/219]\tBatch Time 0.285 (0.291)\tData Load Time 0.000 (0.001)\tLoss 3.4493 (3.4110)\tTop-5 Accuracy 68.241 (69.363)\n",
      "Validation: [0/32]\tBatch Time 0.352 (0.352)\tLoss 8.9721 (8.9721)\tTop-5 Accuracy 21.678 (21.678)\t\n",
      "\n",
      " * LOSS - 8.607, TOP-5 ACCURACY - 23.542, BLEU-4 - 0.035292421097125784\n",
      "\n",
      "\n",
      "Epochs since last improvement: 4\n",
      "\n",
      "Epoch: [19][0/219]\tBatch Time 0.452 (0.452)\tData Load Time 0.146 (0.146)\tLoss 3.1480 (3.1480)\tTop-5 Accuracy 73.000 (73.000)\n",
      "Epoch: [19][100/219]\tBatch Time 0.296 (0.292)\tData Load Time 0.000 (0.002)\tLoss 3.4190 (3.3063)\tTop-5 Accuracy 67.849 (71.410)\n",
      "Epoch: [19][200/219]\tBatch Time 0.285 (0.291)\tData Load Time 0.000 (0.001)\tLoss 3.4062 (3.3109)\tTop-5 Accuracy 70.699 (71.184)\n",
      "Validation: [0/32]\tBatch Time 0.354 (0.354)\tLoss 9.1379 (9.1379)\tTop-5 Accuracy 18.692 (18.692)\t\n",
      "\n",
      " * LOSS - 8.756, TOP-5 ACCURACY - 23.373, BLEU-4 - 0.02938170739640203\n",
      "\n",
      "\n",
      "Epochs since last improvement: 5\n",
      "\n",
      "Epoch: [20][0/219]\tBatch Time 0.438 (0.438)\tData Load Time 0.145 (0.145)\tLoss 3.2927 (3.2927)\tTop-5 Accuracy 72.051 (72.051)\n",
      "Epoch: [20][100/219]\tBatch Time 0.281 (0.290)\tData Load Time 0.000 (0.002)\tLoss 3.3254 (3.1639)\tTop-5 Accuracy 71.709 (73.438)\n",
      "Epoch: [20][200/219]\tBatch Time 0.285 (0.290)\tData Load Time 0.000 (0.001)\tLoss 3.2150 (3.2033)\tTop-5 Accuracy 72.222 (72.762)\n",
      "Validation: [0/32]\tBatch Time 0.411 (0.411)\tLoss 9.2595 (9.2595)\tTop-5 Accuracy 22.687 (22.687)\t\n",
      "\n",
      " * LOSS - 8.812, TOP-5 ACCURACY - 23.193, BLEU-4 - 0.03491375713562169\n",
      "\n",
      "\n",
      "Epochs since last improvement: 6\n",
      "\n",
      "Epoch: [21][0/219]\tBatch Time 0.446 (0.446)\tData Load Time 0.147 (0.147)\tLoss 3.0016 (3.0016)\tTop-5 Accuracy 76.839 (76.839)\n",
      "Epoch: [21][100/219]\tBatch Time 0.298 (0.291)\tData Load Time 0.000 (0.002)\tLoss 3.0461 (3.0814)\tTop-5 Accuracy 72.512 (74.803)\n",
      "Epoch: [21][200/219]\tBatch Time 0.289 (0.290)\tData Load Time 0.000 (0.001)\tLoss 3.1395 (3.1086)\tTop-5 Accuracy 75.000 (74.283)\n",
      "Validation: [0/32]\tBatch Time 0.357 (0.357)\tLoss 8.3059 (8.3059)\tTop-5 Accuracy 22.741 (22.741)\t\n",
      "\n",
      " * LOSS - 8.860, TOP-5 ACCURACY - 22.306, BLEU-4 - 0.0345704625740284\n",
      "\n",
      "\n",
      "Epochs since last improvement: 7\n",
      "\n",
      "Epoch: [22][0/219]\tBatch Time 0.448 (0.448)\tData Load Time 0.148 (0.148)\tLoss 2.9015 (2.9015)\tTop-5 Accuracy 80.711 (80.711)\n",
      "Epoch: [22][100/219]\tBatch Time 0.290 (0.290)\tData Load Time 0.000 (0.002)\tLoss 3.1043 (2.9890)\tTop-5 Accuracy 76.000 (76.283)\n",
      "Epoch: [22][200/219]\tBatch Time 0.284 (0.290)\tData Load Time 0.000 (0.001)\tLoss 3.0608 (3.0084)\tTop-5 Accuracy 74.785 (75.945)\n",
      "Validation: [0/32]\tBatch Time 0.363 (0.363)\tLoss 8.8314 (8.8314)\tTop-5 Accuracy 20.370 (20.370)\t\n",
      "\n",
      " * LOSS - 8.995, TOP-5 ACCURACY - 21.977, BLEU-4 - 0.04210913052177572\n",
      "\n",
      "Epoch: [23][0/219]\tBatch Time 0.452 (0.452)\tData Load Time 0.149 (0.149)\tLoss 2.9820 (2.9820)\tTop-5 Accuracy 79.337 (79.337)\n",
      "Epoch: [23][100/219]\tBatch Time 0.295 (0.292)\tData Load Time 0.000 (0.002)\tLoss 2.9231 (2.8618)\tTop-5 Accuracy 78.072 (78.392)\n",
      "Epoch: [23][200/219]\tBatch Time 0.283 (0.290)\tData Load Time 0.000 (0.001)\tLoss 3.0106 (2.9176)\tTop-5 Accuracy 75.827 (77.444)\n",
      "Validation: [0/32]\tBatch Time 0.360 (0.360)\tLoss 8.5577 (8.5577)\tTop-5 Accuracy 25.076 (25.076)\t\n",
      "\n",
      " * LOSS - 8.946, TOP-5 ACCURACY - 23.104, BLEU-4 - 0.03591659719786085\n",
      "\n",
      "\n",
      "Epochs since last improvement: 1\n",
      "\n",
      "Epoch: [24][0/219]\tBatch Time 0.452 (0.452)\tData Load Time 0.147 (0.147)\tLoss 2.8430 (2.8430)\tTop-5 Accuracy 77.863 (77.863)\n",
      "Epoch: [24][100/219]\tBatch Time 0.290 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.9210 (2.8135)\tTop-5 Accuracy 77.428 (79.113)\n",
      "Epoch: [24][200/219]\tBatch Time 0.281 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.8561 (2.8397)\tTop-5 Accuracy 79.330 (78.641)\n",
      "Validation: [0/32]\tBatch Time 0.357 (0.357)\tLoss 8.7787 (8.7787)\tTop-5 Accuracy 21.587 (21.587)\t\n",
      "\n",
      " * LOSS - 9.046, TOP-5 ACCURACY - 22.376, BLEU-4 - 0.04056295932034621\n",
      "\n",
      "\n",
      "Epochs since last improvement: 2\n",
      "\n",
      "Epoch: [25][0/219]\tBatch Time 0.448 (0.448)\tData Load Time 0.145 (0.145)\tLoss 2.7008 (2.7008)\tTop-5 Accuracy 78.238 (78.238)\n",
      "Epoch: [25][100/219]\tBatch Time 0.277 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.6486 (2.7358)\tTop-5 Accuracy 81.845 (80.311)\n",
      "Epoch: [25][200/219]\tBatch Time 0.284 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.8469 (2.7646)\tTop-5 Accuracy 77.898 (79.836)\n",
      "Validation: [0/32]\tBatch Time 0.353 (0.353)\tLoss 8.8589 (8.8589)\tTop-5 Accuracy 22.680 (22.680)\t\n",
      "\n",
      " * LOSS - 9.242, TOP-5 ACCURACY - 21.728, BLEU-4 - 0.03269840860243825\n",
      "\n",
      "\n",
      "Epochs since last improvement: 3\n",
      "\n",
      "Epoch: [26][0/219]\tBatch Time 0.447 (0.447)\tData Load Time 0.146 (0.146)\tLoss 2.5625 (2.5625)\tTop-5 Accuracy 83.636 (83.636)\n",
      "Epoch: [26][100/219]\tBatch Time 0.289 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.8953 (2.6667)\tTop-5 Accuracy 77.719 (81.068)\n",
      "Epoch: [26][200/219]\tBatch Time 0.293 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.7562 (2.6848)\tTop-5 Accuracy 78.481 (80.810)\n",
      "Validation: [0/32]\tBatch Time 2.222 (2.222)\tLoss 9.5513 (9.5513)\tTop-5 Accuracy 19.335 (19.335)\t\n",
      "\n",
      " * LOSS - 9.284, TOP-5 ACCURACY - 21.948, BLEU-4 - 0.03640115470843251\n",
      "\n",
      "\n",
      "Epochs since last improvement: 4\n",
      "\n",
      "Epoch: [27][0/219]\tBatch Time 0.443 (0.443)\tData Load Time 0.148 (0.148)\tLoss 2.5188 (2.5188)\tTop-5 Accuracy 82.842 (82.842)\n",
      "Epoch: [27][100/219]\tBatch Time 0.295 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.7577 (2.5773)\tTop-5 Accuracy 79.455 (82.395)\n",
      "Epoch: [27][200/219]\tBatch Time 0.305 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.6262 (2.6101)\tTop-5 Accuracy 80.568 (81.879)\n",
      "Validation: [0/32]\tBatch Time 0.359 (0.359)\tLoss 9.2636 (9.2636)\tTop-5 Accuracy 21.782 (21.782)\t\n",
      "\n",
      " * LOSS - 9.356, TOP-5 ACCURACY - 20.562, BLEU-4 - 0.03378077134785357\n",
      "\n",
      "\n",
      "Epochs since last improvement: 5\n",
      "\n",
      "Epoch: [28][0/219]\tBatch Time 0.457 (0.457)\tData Load Time 0.147 (0.147)\tLoss 2.3209 (2.3209)\tTop-5 Accuracy 86.190 (86.190)\n",
      "Epoch: [28][100/219]\tBatch Time 0.292 (0.290)\tData Load Time 0.000 (0.002)\tLoss 2.5565 (2.5103)\tTop-5 Accuracy 80.964 (83.337)\n",
      "Epoch: [28][200/219]\tBatch Time 0.286 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.5924 (2.5401)\tTop-5 Accuracy 80.052 (82.926)\n",
      "Validation: [0/32]\tBatch Time 0.361 (0.361)\tLoss 8.7969 (8.7969)\tTop-5 Accuracy 20.721 (20.721)\t\n",
      "\n",
      " * LOSS - 9.341, TOP-5 ACCURACY - 21.369, BLEU-4 - 0.03724309631854711\n",
      "\n",
      "\n",
      "Epochs since last improvement: 6\n",
      "\n",
      "Epoch: [29][0/219]\tBatch Time 0.454 (0.454)\tData Load Time 0.149 (0.149)\tLoss 2.4109 (2.4109)\tTop-5 Accuracy 83.217 (83.217)\n",
      "Epoch: [29][100/219]\tBatch Time 0.284 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.5376 (2.4488)\tTop-5 Accuracy 83.965 (84.253)\n",
      "Epoch: [29][200/219]\tBatch Time 0.291 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.6320 (2.4795)\tTop-5 Accuracy 81.627 (83.700)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: [0/32]\tBatch Time 0.367 (0.367)\tLoss 9.7515 (9.7515)\tTop-5 Accuracy 20.059 (20.059)\t\n",
      "\n",
      " * LOSS - 9.470, TOP-5 ACCURACY - 21.449, BLEU-4 - 0.031838689444593546\n",
      "\n",
      "\n",
      "Epochs since last improvement: 7\n",
      "\n",
      "Epoch: [30][0/219]\tBatch Time 0.446 (0.446)\tData Load Time 0.148 (0.148)\tLoss 2.3428 (2.3428)\tTop-5 Accuracy 84.697 (84.697)\n",
      "Epoch: [30][100/219]\tBatch Time 0.298 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.2875 (2.3863)\tTop-5 Accuracy 85.176 (84.872)\n",
      "Epoch: [30][200/219]\tBatch Time 0.286 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.4969 (2.4213)\tTop-5 Accuracy 85.024 (84.407)\n",
      "Validation: [0/32]\tBatch Time 0.359 (0.359)\tLoss 9.5167 (9.5167)\tTop-5 Accuracy 21.856 (21.856)\t\n",
      "\n",
      " * LOSS - 9.522, TOP-5 ACCURACY - 21.539, BLEU-4 - 0.035088314514798026\n",
      "\n",
      "\n",
      "Epochs since last improvement: 8\n",
      "\n",
      "\n",
      "DECAYING learning rate.\n",
      "The new learning rate is 0.000320\n",
      "\n",
      "Epoch: [31][0/219]\tBatch Time 0.453 (0.453)\tData Load Time 0.148 (0.148)\tLoss 2.2985 (2.2985)\tTop-5 Accuracy 85.279 (85.279)\n",
      "Epoch: [31][100/219]\tBatch Time 0.291 (0.292)\tData Load Time 0.000 (0.002)\tLoss 2.3319 (2.3227)\tTop-5 Accuracy 85.575 (85.617)\n",
      "Epoch: [31][200/219]\tBatch Time 0.275 (0.291)\tData Load Time 0.000 (0.001)\tLoss 2.4207 (2.3383)\tTop-5 Accuracy 86.416 (85.534)\n",
      "Validation: [0/32]\tBatch Time 0.374 (0.374)\tLoss 8.8470 (8.8470)\tTop-5 Accuracy 22.350 (22.350)\t\n",
      "\n",
      " * LOSS - 9.603, TOP-5 ACCURACY - 21.250, BLEU-4 - 0.03445615342433179\n",
      "\n",
      "\n",
      "Epochs since last improvement: 9\n",
      "\n",
      "Epoch: [32][0/219]\tBatch Time 0.518 (0.518)\tData Load Time 0.201 (0.201)\tLoss 2.1094 (2.1094)\tTop-5 Accuracy 86.577 (86.577)\n",
      "Epoch: [32][100/219]\tBatch Time 0.299 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.1168 (2.2641)\tTop-5 Accuracy 88.532 (86.467)\n",
      "Epoch: [32][200/219]\tBatch Time 0.295 (0.291)\tData Load Time 0.000 (0.001)\tLoss 2.3651 (2.2886)\tTop-5 Accuracy 85.401 (86.181)\n",
      "Validation: [0/32]\tBatch Time 0.404 (0.404)\tLoss 9.6058 (9.6058)\tTop-5 Accuracy 21.965 (21.965)\t\n",
      "\n",
      " * LOSS - 9.586, TOP-5 ACCURACY - 20.732, BLEU-4 - 0.03778683907995347\n",
      "\n",
      "\n",
      "Epochs since last improvement: 10\n",
      "\n",
      "Epoch: [33][0/219]\tBatch Time 0.451 (0.451)\tData Load Time 0.149 (0.149)\tLoss 2.2540 (2.2540)\tTop-5 Accuracy 87.848 (87.848)\n",
      "Epoch: [33][100/219]\tBatch Time 0.282 (0.292)\tData Load Time 0.000 (0.002)\tLoss 2.2058 (2.2213)\tTop-5 Accuracy 85.163 (86.907)\n",
      "Epoch: [33][200/219]\tBatch Time 0.292 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.2843 (2.2458)\tTop-5 Accuracy 85.504 (86.549)\n",
      "Validation: [0/32]\tBatch Time 0.367 (0.367)\tLoss 9.5451 (9.5451)\tTop-5 Accuracy 23.175 (23.175)\t\n",
      "\n",
      " * LOSS - 9.677, TOP-5 ACCURACY - 20.891, BLEU-4 - 0.03717240363102661\n",
      "\n",
      "\n",
      "Epochs since last improvement: 11\n",
      "\n",
      "Epoch: [34][0/219]\tBatch Time 0.454 (0.454)\tData Load Time 0.145 (0.145)\tLoss 2.1336 (2.1336)\tTop-5 Accuracy 88.787 (88.787)\n",
      "Epoch: [34][100/219]\tBatch Time 0.293 (0.290)\tData Load Time 0.000 (0.002)\tLoss 2.1128 (2.1837)\tTop-5 Accuracy 88.041 (87.483)\n",
      "Epoch: [34][200/219]\tBatch Time 0.290 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.3368 (2.2061)\tTop-5 Accuracy 84.536 (87.146)\n",
      "Validation: [0/32]\tBatch Time 0.355 (0.355)\tLoss 10.2202 (10.2202)\tTop-5 Accuracy 20.423 (20.423)\t\n",
      "\n",
      " * LOSS - 9.757, TOP-5 ACCURACY - 20.901, BLEU-4 - 0.0421262608874663\n",
      "\n",
      "Epoch: [35][0/219]\tBatch Time 0.444 (0.444)\tData Load Time 0.145 (0.145)\tLoss 2.1095 (2.1095)\tTop-5 Accuracy 88.279 (88.279)\n",
      "Epoch: [35][100/219]\tBatch Time 0.292 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.1395 (2.1572)\tTop-5 Accuracy 87.056 (87.545)\n",
      "Epoch: [35][200/219]\tBatch Time 0.294 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.1025 (2.1709)\tTop-5 Accuracy 89.136 (87.486)\n",
      "Validation: [0/32]\tBatch Time 0.723 (0.723)\tLoss 9.4141 (9.4141)\tTop-5 Accuracy 22.045 (22.045)\t\n",
      "\n",
      " * LOSS - 9.870, TOP-5 ACCURACY - 20.423, BLEU-4 - 0.04104090148696217\n",
      "\n",
      "\n",
      "Epochs since last improvement: 1\n",
      "\n",
      "Epoch: [36][0/219]\tBatch Time 0.447 (0.447)\tData Load Time 0.148 (0.148)\tLoss 2.0815 (2.0815)\tTop-5 Accuracy 87.371 (87.371)\n",
      "Epoch: [36][100/219]\tBatch Time 0.299 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.0726 (2.1173)\tTop-5 Accuracy 89.120 (88.087)\n",
      "Epoch: [36][200/219]\tBatch Time 0.285 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.1911 (2.1357)\tTop-5 Accuracy 88.418 (87.844)\n",
      "Validation: [0/32]\tBatch Time 0.362 (0.362)\tLoss 9.4661 (9.4661)\tTop-5 Accuracy 23.053 (23.053)\t\n",
      "\n",
      " * LOSS - 9.841, TOP-5 ACCURACY - 20.592, BLEU-4 - 0.03381920025676004\n",
      "\n",
      "\n",
      "Epochs since last improvement: 2\n",
      "\n",
      "Epoch: [37][0/219]\tBatch Time 0.443 (0.443)\tData Load Time 0.147 (0.147)\tLoss 2.0634 (2.0634)\tTop-5 Accuracy 88.378 (88.378)\n",
      "Epoch: [37][100/219]\tBatch Time 0.287 (0.292)\tData Load Time 0.000 (0.002)\tLoss 1.9500 (2.0834)\tTop-5 Accuracy 90.464 (88.398)\n",
      "Epoch: [37][200/219]\tBatch Time 0.285 (0.291)\tData Load Time 0.000 (0.001)\tLoss 2.0563 (2.0976)\tTop-5 Accuracy 88.030 (88.293)\n",
      "Validation: [0/32]\tBatch Time 3.021 (3.021)\tLoss 9.9800 (9.9800)\tTop-5 Accuracy 19.942 (19.942)\t\n",
      "\n",
      " * LOSS - 9.923, TOP-5 ACCURACY - 20.572, BLEU-4 - 0.03563824757776043\n",
      "\n",
      "\n",
      "Epochs since last improvement: 3\n",
      "\n",
      "Epoch: [38][0/219]\tBatch Time 0.452 (0.452)\tData Load Time 0.146 (0.146)\tLoss 1.9127 (1.9127)\tTop-5 Accuracy 90.521 (90.521)\n",
      "Epoch: [38][100/219]\tBatch Time 0.297 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.0412 (2.0581)\tTop-5 Accuracy 88.124 (88.655)\n",
      "Epoch: [38][200/219]\tBatch Time 0.284 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.2500 (2.0747)\tTop-5 Accuracy 86.575 (88.427)\n",
      "Validation: [0/32]\tBatch Time 0.363 (0.363)\tLoss 9.9248 (9.9248)\tTop-5 Accuracy 22.424 (22.424)\t\n",
      "\n",
      " * LOSS - 9.956, TOP-5 ACCURACY - 20.213, BLEU-4 - 0.03355561933047663\n",
      "\n",
      "\n",
      "Epochs since last improvement: 4\n",
      "\n",
      "Epoch: [39][0/219]\tBatch Time 0.445 (0.445)\tData Load Time 0.146 (0.146)\tLoss 1.9673 (1.9673)\tTop-5 Accuracy 88.976 (88.976)\n",
      "Epoch: [39][100/219]\tBatch Time 0.293 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.0517 (2.0247)\tTop-5 Accuracy 89.713 (89.041)\n",
      "Epoch: [39][200/219]\tBatch Time 0.273 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.1420 (2.0455)\tTop-5 Accuracy 88.187 (88.722)\n",
      "Validation: [0/32]\tBatch Time 0.357 (0.357)\tLoss 10.3325 (10.3325)\tTop-5 Accuracy 16.772 (16.772)\t\n",
      "\n",
      " * LOSS - 9.989, TOP-5 ACCURACY - 19.894, BLEU-4 - 0.03235614032664502\n",
      "\n",
      "\n",
      "Epochs since last improvement: 5\n",
      "\n",
      "Epoch: [40][0/219]\tBatch Time 0.452 (0.452)\tData Load Time 0.148 (0.148)\tLoss 1.9733 (1.9733)\tTop-5 Accuracy 89.630 (89.630)\n",
      "Epoch: [40][100/219]\tBatch Time 0.285 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.0672 (2.0034)\tTop-5 Accuracy 90.451 (89.142)\n",
      "Epoch: [40][200/219]\tBatch Time 0.293 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.0244 (2.0201)\tTop-5 Accuracy 88.131 (88.962)\n",
      "Validation: [0/32]\tBatch Time 0.355 (0.355)\tLoss 9.9250 (9.9250)\tTop-5 Accuracy 18.812 (18.812)\t\n",
      "\n",
      " * LOSS - 10.167, TOP-5 ACCURACY - 20.353, BLEU-4 - 0.03223871699742074\n",
      "\n",
      "\n",
      "Epochs since last improvement: 6\n",
      "\n",
      "Epoch: [41][0/219]\tBatch Time 0.451 (0.451)\tData Load Time 0.147 (0.147)\tLoss 1.9206 (1.9206)\tTop-5 Accuracy 90.727 (90.727)\n",
      "Epoch: [41][100/219]\tBatch Time 0.276 (0.291)\tData Load Time 0.000 (0.002)\tLoss 2.0294 (1.9822)\tTop-5 Accuracy 90.000 (89.392)\n",
      "Epoch: [41][200/219]\tBatch Time 0.281 (0.291)\tData Load Time 0.000 (0.001)\tLoss 2.0680 (1.9920)\tTop-5 Accuracy 89.744 (89.210)\n",
      "Validation: [0/32]\tBatch Time 0.357 (0.357)\tLoss 10.2758 (10.2758)\tTop-5 Accuracy 19.585 (19.585)\t\n",
      "\n",
      " * LOSS - 10.191, TOP-5 ACCURACY - 19.904, BLEU-4 - 0.039059852288476055\n",
      "\n",
      "\n",
      "Epochs since last improvement: 7\n",
      "\n",
      "Epoch: [42][0/219]\tBatch Time 0.448 (0.448)\tData Load Time 0.149 (0.149)\tLoss 2.0402 (2.0402)\tTop-5 Accuracy 90.026 (90.026)\n",
      "Epoch: [42][100/219]\tBatch Time 0.285 (0.290)\tData Load Time 0.000 (0.002)\tLoss 1.8472 (1.9590)\tTop-5 Accuracy 90.451 (89.569)\n",
      "Epoch: [42][200/219]\tBatch Time 0.288 (0.290)\tData Load Time 0.000 (0.001)\tLoss 1.9829 (1.9680)\tTop-5 Accuracy 90.130 (89.469)\n",
      "Validation: [0/32]\tBatch Time 0.365 (0.365)\tLoss 9.8181 (9.8181)\tTop-5 Accuracy 17.365 (17.365)\t\n",
      "\n",
      " * LOSS - 10.131, TOP-5 ACCURACY - 19.994, BLEU-4 - 0.034343736756491994\n",
      "\n",
      "\n",
      "Epochs since last improvement: 8\n",
      "\n",
      "\n",
      "DECAYING learning rate.\n",
      "The new learning rate is 0.000256\n",
      "\n",
      "Epoch: [43][0/219]\tBatch Time 0.440 (0.440)\tData Load Time 0.147 (0.147)\tLoss 1.8972 (1.8972)\tTop-5 Accuracy 89.295 (89.295)\n",
      "Epoch: [43][100/219]\tBatch Time 0.291 (0.291)\tData Load Time 0.000 (0.002)\tLoss 1.8781 (1.9227)\tTop-5 Accuracy 91.960 (89.882)\n",
      "Epoch: [43][200/219]\tBatch Time 0.266 (0.290)\tData Load Time 0.000 (0.001)\tLoss 2.1108 (1.9315)\tTop-5 Accuracy 88.854 (89.747)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: [0/32]\tBatch Time 0.412 (0.412)\tLoss 9.8847 (9.8847)\tTop-5 Accuracy 22.356 (22.356)\t\n",
      "\n",
      " * LOSS - 10.204, TOP-5 ACCURACY - 20.213, BLEU-4 - 0.03647374456474386\n",
      "\n",
      "\n",
      "Epochs since last improvement: 9\n",
      "\n",
      "Epoch: [44][0/219]\tBatch Time 0.450 (0.450)\tData Load Time 0.148 (0.148)\tLoss 1.9379 (1.9379)\tTop-5 Accuracy 90.231 (90.231)\n",
      "Epoch: [44][100/219]\tBatch Time 0.285 (0.292)\tData Load Time 0.000 (0.002)\tLoss 1.8453 (1.8879)\tTop-5 Accuracy 90.152 (90.125)\n",
      "Epoch: [44][200/219]\tBatch Time 0.286 (0.290)\tData Load Time 0.000 (0.001)\tLoss 1.9239 (1.9032)\tTop-5 Accuracy 89.182 (89.930)\n",
      "Validation: [0/32]\tBatch Time 0.360 (0.360)\tLoss 11.5109 (11.5109)\tTop-5 Accuracy 15.987 (15.987)\t\n",
      "\n",
      " * LOSS - 10.235, TOP-5 ACCURACY - 20.243, BLEU-4 - 0.031693227286111424\n",
      "\n",
      "\n",
      "Epochs since last improvement: 10\n",
      "\n",
      "Epoch: [45][0/219]\tBatch Time 0.440 (0.440)\tData Load Time 0.148 (0.148)\tLoss 1.8740 (1.8740)\tTop-5 Accuracy 91.105 (91.105)\n",
      "Epoch: [45][100/219]\tBatch Time 0.296 (0.291)\tData Load Time 0.000 (0.002)\tLoss 1.8069 (1.8794)\tTop-5 Accuracy 90.144 (90.140)\n",
      "Epoch: [45][200/219]\tBatch Time 0.295 (0.290)\tData Load Time 0.000 (0.001)\tLoss 1.9357 (1.8907)\tTop-5 Accuracy 88.235 (89.972)\n",
      "Validation: [0/32]\tBatch Time 4.229 (4.229)\tLoss 10.7437 (10.7437)\tTop-5 Accuracy 17.846 (17.846)\t\n",
      "\n",
      " * LOSS - 10.302, TOP-5 ACCURACY - 19.655, BLEU-4 - 0.03567434168430317\n",
      "\n",
      "\n",
      "Epochs since last improvement: 11\n",
      "\n",
      "Epoch: [46][0/219]\tBatch Time 0.450 (0.450)\tData Load Time 0.146 (0.146)\tLoss 1.8246 (1.8246)\tTop-5 Accuracy 90.428 (90.428)\n",
      "Epoch: [46][100/219]\tBatch Time 0.290 (0.291)\tData Load Time 0.000 (0.002)\tLoss 1.8543 (1.8545)\tTop-5 Accuracy 91.049 (90.346)\n",
      "Epoch: [46][200/219]\tBatch Time 0.288 (0.290)\tData Load Time 0.000 (0.001)\tLoss 1.8681 (1.8666)\tTop-5 Accuracy 89.840 (90.213)\n",
      "Validation: [0/32]\tBatch Time 0.361 (0.361)\tLoss 10.0575 (10.0575)\tTop-5 Accuracy 22.985 (22.985)\t\n",
      "\n",
      " * LOSS - 10.484, TOP-5 ACCURACY - 20.094, BLEU-4 - 0.033409005574782824\n",
      "\n",
      "\n",
      "Epochs since last improvement: 12\n",
      "\n",
      "Epoch: [47][0/219]\tBatch Time 0.435 (0.435)\tData Load Time 0.148 (0.148)\tLoss 1.9439 (1.9439)\tTop-5 Accuracy 89.021 (89.021)\n",
      "Epoch: [47][100/219]\tBatch Time 0.277 (0.291)\tData Load Time 0.000 (0.002)\tLoss 1.8098 (1.8483)\tTop-5 Accuracy 90.313 (90.397)\n",
      "Epoch: [47][200/219]\tBatch Time 0.294 (0.290)\tData Load Time 0.000 (0.001)\tLoss 1.8053 (1.8556)\tTop-5 Accuracy 89.976 (90.346)\n",
      "Validation: [0/32]\tBatch Time 0.363 (0.363)\tLoss 10.4230 (10.4230)\tTop-5 Accuracy 17.485 (17.485)\t\n",
      "\n",
      " * LOSS - 10.394, TOP-5 ACCURACY - 19.286, BLEU-4 - 0.03705322083077776\n",
      "\n",
      "\n",
      "Epochs since last improvement: 13\n",
      "\n",
      "Epoch: [48][0/219]\tBatch Time 0.444 (0.444)\tData Load Time 0.148 (0.148)\tLoss 1.8496 (1.8496)\tTop-5 Accuracy 90.186 (90.186)\n",
      "Epoch: [48][100/219]\tBatch Time 0.289 (0.291)\tData Load Time 0.000 (0.002)\tLoss 1.8323 (1.8252)\tTop-5 Accuracy 90.933 (90.676)\n",
      "Epoch: [48][200/219]\tBatch Time 0.292 (0.290)\tData Load Time 0.000 (0.001)\tLoss 1.8064 (1.8429)\tTop-5 Accuracy 92.092 (90.448)\n",
      "Validation: [0/32]\tBatch Time 0.372 (0.372)\tLoss 10.4521 (10.4521)\tTop-5 Accuracy 18.560 (18.560)\t\n",
      "\n",
      " * LOSS - 10.467, TOP-5 ACCURACY - 19.964, BLEU-4 - 0.02884270293540744\n",
      "\n",
      "\n",
      "Epochs since last improvement: 14\n",
      "\n",
      "Epoch: [49][0/219]\tBatch Time 0.456 (0.456)\tData Load Time 0.146 (0.146)\tLoss 1.8436 (1.8436)\tTop-5 Accuracy 90.191 (90.191)\n",
      "Epoch: [49][100/219]\tBatch Time 0.289 (0.291)\tData Load Time 0.000 (0.002)\tLoss 1.8082 (1.8191)\tTop-5 Accuracy 90.741 (90.693)\n",
      "Epoch: [49][200/219]\tBatch Time 0.279 (0.290)\tData Load Time 0.000 (0.001)\tLoss 1.9746 (1.8272)\tTop-5 Accuracy 88.663 (90.640)\n",
      "Validation: [0/32]\tBatch Time 0.357 (0.357)\tLoss 9.7707 (9.7707)\tTop-5 Accuracy 18.598 (18.598)\t\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
